# TODOs

- [ ] Add references to the binaries in dataset.

## Intro / Background

Binary code similarity detection (BCSD) is becoming increasingly important as the rate of production and modularity of software grows.
Modern software is almost never written from scratch, and is becoming increasingly reliant on external libraries.
For reverse engineers, reducing the amount of repetitive assembly functions to analyze is important,
    as it allows them to be more efficient and focus on the custom parts of a binary.
When libraries are statically linked to the binary, it is important to quickly identify which functions
    are part of common external libraries to minimize repetitive work.
Furthermore, if a vulnerability is found in a library, it is important to quickly identify if an unknown binary or firmware
    is using the vulnerable library, so that its impact can be mitigated.
Other applications of BCSD include license compliance and plagiarism detection.

### Contributions

We develop an elementary approach to BCSD purely based on the recent advancements in large language models (LLM).

Instead of generating a numerical feature vector for a given assembly function, we generate a feature set containing
human readable elements.

TBD: how does this method compare to SOTA?

Advantages:

TBD: We show that this method scales with the capabilities of large language models. 
    (This is great since significant investments & research goes to LLMs, blah blah)
- Scales very well with the capabilities of LLMs.
- No pre-training, no fine tuning, works for any LLM out of the box.

Humans can verify the feature set generated by our method.
    (In an ideal world, we would not need human verification. Current methods are not perfect so human verif is still needed.
     Our method eases this process and can more easily be debugged.)

## Related Work

### Static Analysis

Traditional methods make use of static analysis to detect clone assembly routines. With these methods, a trade-off has
to be made between the robustness to obfuscation and architecture differences, and the performance of the algorithm. [1]
Control flow graph analysis and comparison [3, 4] is known to be very robust to syntactic differences, but often involves "NP-hard"
problems. Other algorithms that use heuristics such as instruction frequency, longest-common-subsequence, or hashes [5, 6, 7] are more
efficient, but tend to fixate on the syntactic elements and their ordering rather than the semantics.

### Dynamic Analysis

Dynamic analysis consists of analyzing the features of a binary or code fragment by monitoring its runtime behavior. For BCSD
this method is compute intensive and requires a cross-platform emulator, but completely sidesteps the syntactic aspects of binary code
and solely analyzes the semantics. [2] As such, this method is highly resilient to obfuscations, but requires a sandboxed environment
equiped with complex software.

### Machine Learning Methods

The surge of interest and applications for machine learning in recent years has also affected BCSD.
Most state-of-the-art methods use natural language processing (NLP) to achieve their results [refs].
Notably, recent machine learning approaches try to incorporate the transformer architecture into BCSD tasks [refs].

TODO: Complete this with the methods we are comparing against.

- Others make use of widely available LLMs either during training as data annotation [ref] (CLAP)

## Methodology

### Prompt

- What are the features we extract?
- What type of output do we expect (main different between prompts)?
    - How do we solve repetition.
    - How do we ensure a valid json output?

### Dataset

The dataset is composed of 7 binaries: busybox, coreutils, curl, image-magick, openssl, putty, and sqlite3.
All were compiled using gcc for the following platforms: x86_64, x86_32, arm, mips, powerpc.
For each binary and platform, binary objects were generated for all optimization levels (O0 to O3),
stripped of debug symbols. In total, yeilds 140 different binaries to analyze.
The binaries were dissassembled using IDA Pro, yielding 383_658 assembly routines. Pairs of equivalent
functions from the same platform but distinct optimization level were made for cross optimization
evaluation, and pairs from the same optimization level but different platform were formed for cross
platform evaluation.

### Model

We evaluate these models on our dataset.
- Qwen2.5-Coder [ref] with sizes 0.5B to 7B

### Comparison

Machine learning based methods of BCSD generate a numerical vector embedding for each assembly function [refs], and then compare these vectors
using numerical methods such as cosine similarity. Our method is different, because it generates a JSON object instead of a vector. This has
the unique advantage of being human interpretable, and thus easier to verify. For example, when matching a binary function against a database,
one can base themself on the human readable LLM output to verify that the analysis was done correctly and to assess whether the matched function
is indeed a clone.

Since our generated analysis is not numerical, we use an alternative method to compare two assembly functions. We interpret the JSON structure
as a tree, where booleans, numbers, and string elements are leaves, and non-empty lists and objects fields are nodes. We form a set containing all
root-to-leaf paths, and use jaccard similarity (Intesection over union) to obtain a similarity measure.

QUESTION: Do we need refs for cosine similarity & jaccard?

## Results

- Show results on cross-optimization and cross-architecture (Many different models ran locally).
- Ablation on the number of examples provided.
- Ablation on the model size.
- Ablation on the prompt used, examples of output.
- Show results on commercial models
- Token usage on commercial models

### Human interpretability

Our method offers a distinct advantage over the current state-of-the art, because the feature vectors generated are human interpretable.
Other machine learning based methods generate numerical vector embeddings and compare the vectors using numerical methods such as cosine similarity.

# Refs

1. [A Survey of Binary Code Similarity Detection Techniques](https://www.mdpi.com/2079-9292/13/9/1715)
2. [Binary Code Similiarity Detection](https://ieeexplore.ieee.org/document/9678518)
3. [Scalable Graph-based Bug Search for Firmware Images](https://dl.acm.org/doi/10.1145/2976749.2978370)
4. [Graph-based comparison of Executable Objects](https://www.semanticscholar.org/paper/Graph-based-comparison-of-Executable-Objects-Dullien/7661d4110ef24dea74190f4af69bd206d6253db9)

5. [Detecting Clones Across Microsoft .NET Programming Languages](https://ieeexplore.ieee.org/document/6385136)
6. [Idea: Opcode-Sequence-Based Malware Detection](https://link.springer.com/chapter/10.1007/978-3-642-11747-3_3)
7. [Binary Function Clustering Using Semantic Hashes](https://ieeexplore.ieee.org/document/6406693)

- [Blanket execution: Dynamic similarity testing for program binaries and components](https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/egele)
- [BinSim: Trace-based Semantic Binary Diffing via System Call Sliced Segment Equivalence Checking](https://www.usenix.org/system/files/conference/usenixsecurity17/sec17-ming.pdf)